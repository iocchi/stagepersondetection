# -*- coding: utf-8 -*-
"""StagePerson_AlexNet

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lYl7YZ7zG5U-BkUwl-f73FShD5qxfog6

# Person detection in stage simulator

# AlexNet

##Import 

Import libraries and print some versions.

To use GPU, set `Edit / Notebook settings / Hardware accelerator` to **GPU**.
"""

import os, sys

import numpy as np

import tensorflow as tf
import keras
from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from keras.models import Sequential
from keras.layers import Dense, Activation, Dropout, Flatten,\
                         Conv2D, MaxPooling2D
from keras.layers.normalization import BatchNormalization
from keras import regularizers
from keras import optimizers
from keras.models import load_model

import matplotlib.pyplot as plt


print("Tensorflow version %s" %tf.__version__)
print("Keras version %s" %keras.__version__)


datadir = '.'

train_generator = None
test_generator = None
classnames = None

"""## Load data

Get data from Google folder and set the `datadir` variable below with the path of this folder.

Get Google Drive access

"""
def loadData():
    global train_generator, test_generator, classnames

    trainingset = datadir + '/train/'
    testset = datadir + '/test/'

    batch_size = 32

    train_datagen = ImageDataGenerator(
        rescale = 1. / 255,\
        zoom_range=0.1,\
        #rotation_range=10,\
        width_shift_range=0.1,\
        height_shift_range=0.1,\
        horizontal_flip=True,\
        vertical_flip=False)

    train_generator = train_datagen.flow_from_directory(
        directory=trainingset,
        target_size=(118, 224),
        color_mode="rgb",
        batch_size=batch_size,
        class_mode="categorical",
        shuffle=True)

    test_datagen = ImageDataGenerator(
        rescale = 1. / 255)

    test_generator = test_datagen.flow_from_directory(
        directory=testset,
        target_size=(118, 224),
        color_mode="rgb",
        batch_size=batch_size//2,
        class_mode="categorical",
        shuffle=False
    )

    num_samples = train_generator.n
    num_classes = train_generator.num_classes
    input_shape = train_generator.image_shape

    classnames = [k for k,v in train_generator.class_indices.items()]

    print("Image input %s" %str(input_shape))
    print("Classes: %r" %classnames)

    print('Loaded %d training samples from %d classes.' %(num_samples,num_classes))
    print('Loaded %d test samples from %d classes.' %(test_generator.n,test_generator.num_classes))

    return input_shape, num_classes 
    

"""##Show *n* random images

"""
def showImages(n=3):
    x,y = train_generator.next()
    # x,y size is train_generator.batch_size

    for i in range(0,n):
        image = x[i]
        label = y[i].argmax()  # categorical from one-hot-encoding
        print(classnames[label])
        plt.imshow(image)
        plt.show()

"""##AlexNet

Create a new model inspired by AlexNet.

Note: if you want to load a pre-trained model on this dataset, go to next section.
"""

def StagePersonNet(input_shape, num_classes, regl2 = 0.001, lr=0.001):

    model = Sequential()

    # C1 Convolutional Layer 
    model.add(Conv2D(filters=96, input_shape=input_shape, kernel_size=(11,11),\
                     strides=(2,4), padding='valid'))
    model.add(Activation('relu'))
    # Pooling
    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))
    # Batch Normalisation before passing it to the next layer
    model.add(BatchNormalization())

    # C2 Convolutional Layer
    model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))
    model.add(Activation('relu'))
    # Pooling
    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))
    # Batch Normalisation
    model.add(BatchNormalization())

    # C3 Convolutional Layer
    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))
    model.add(Activation('relu'))
    # Pooling
    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))
    # Batch Normalisation
    model.add(BatchNormalization())

    # Flatten
    model.add(Flatten())

    flatten_shape = (input_shape[0]*input_shape[1]*input_shape[2],)
    
    # D1 Dense Layer
    model.add(Dense(1000, kernel_regularizer=regularizers.l2(regl2)))
    model.add(Activation('relu'))
    # Dropout
    #model.add(Dropout(0.4))
    # Batch Normalisation
    model.add(BatchNormalization())

    # D2 Dense Layer
    model.add(Dense(100,kernel_regularizer=regularizers.l2(regl2)))
    model.add(Activation('relu'))
    # Dropout
    #model.add(Dropout(0.4))
    # Batch Normalisation
    model.add(BatchNormalization())

    # Output Layer
    model.add(Dense(num_classes))
    model.add(Activation('softmax'))

    # Compile

    adam = optimizers.Adam(lr=lr)
    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])

    return model


"""###Load a trained model

Load a model already trained on this data set (i.e., saved with save function show in the next section).
"""


def loadModel(problem, lr=0.001):
    models_dir = datadir + '/models/'
    filename = os.path.join(models_dir, '%s.h5' %problem)
    try:
        model = load_model(filename)
        print("\nModel loaded successfully from file %s\n" %filename)

        adam = optimizers.Adam(lr=lr)
        model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])

    except OSError:    
        print("\nModel file %s not found!!!\n" %filename)
        model = None
    return model


"""## Train


"""

def trainModel(model, epochs = 30):

    global train_generator, test_generator

    steps_per_epoch=train_generator.n//train_generator.batch_size+1
    val_steps=test_generator.n//test_generator.batch_size+1
    try:
        history = model.fit(train_generator, epochs=epochs, verbose=1,\
                        steps_per_epoch=steps_per_epoch,\
                        validation_data=test_generator,\
                        validation_steps=val_steps)
    except KeyboardInterrupt:
        pass

"""##Save the model"""


def saveModel(model, problem):
    models_dir = datadir + '/models/'
    filename = os.path.join(models_dir, '%s.h5' %problem)
    model.save(filename)
    print("\nModel saved successfully on file %s\n" %filename)


"""##Evaluate the model

Accuracy on test set
"""

def evalModel(model):

    global train_generator, test_generator

    testset = datadir + '/test/'

    test_datagen = ImageDataGenerator(
        rescale = 1. / 255)

    test_generator = test_datagen.flow_from_directory(
        directory=testset,
        target_size=(118, 224),
        color_mode="rgb",
        batch_size=1,
        class_mode="categorical",
        shuffle=False
    )

    print('Loaded %d test samples from %d classes.' %(test_generator.n,test_generator.num_classes))

    val_steps=test_generator.n
    loss, acc = model.evaluate(test_generator,verbose=1,steps=val_steps)
    print('Test loss: %f' %loss)
    print('Test accuracy: %f' %acc)


def inputImage(imagefile):
    img = load_img(imagefile, target_size=(118, 224), color_mode="rgb")
    arr = img_to_array(img) / 255
    inp = np.array([arr])  # Convert single image to a batch.
    return inp


def train(create=False, epochs=30, lr=0.001):

    input_shape, num_classes = loadData()

    if create:
        model = StagePersonNet(input_shape,num_classes)
    else:
        model = loadModel('stageperson5_20210425_v3', lr)

    #model.summary()

    trainModel(model,epochs)

    saveModel(model, 'stageperson5_20210425_v3')


def test():

    classnames = ['blue', 'green', 'none', 'red', 'yellow']

    model = loadModel('stageperson5_v3')
    #model.summary()

    evalModel(model)

    p1 = inputImage('test/none/20210425-170843-photo.jpg')
    p2 = inputImage('test/yellow/20210425-171333-photo.jpg')
    p3 = inputImage('test/blue/20210425-170928-photo.jpg')
    p4 = inputImage('test/green/20210425-171007-photo.jpg')
    p5 = inputImage('test/red/20210425-220733-photo.jpg')

    c1 = model.predict(p1)
    c2 = model.predict(p2)
    c3 = model.predict(p3)
    c4 = model.predict(p4)
    c5 = model.predict(p5)

    print("none:   %.3f  %s" %(np.max(c1), classnames[np.argmax(c1)]))
    print("yellow: %.3f  %s" %(np.max(c2), classnames[np.argmax(c2)]))
    print("blue:   %.3f  %s" %(np.max(c3), classnames[np.argmax(c3)]))
    print("green:  %.3f  %s" %(np.max(c4), classnames[np.argmax(c4)]))
    print("red:    %.3f  %s" %(np.max(c5), classnames[np.argmax(c5)]))


if __name__=='__main__':

#    train(create=True, epochs=30, lr=0.001)
#    train(create=False, epochs=10, lr=0.0005)
#    train(create=False, epochs=10, lr=0.0004)
#    train(create=False, epochs=10, lr=0.0003)
#    train(create=False, epochs=10, lr=0.0002)
#    train(create=False, epochs=10, lr=0.0001)

    test()

